{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "text = str('''\n",
    "    <script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <script>\n",
       "  function code_toggle() {\n",
       "    if (code_shown){\n",
       "      $('div.input').hide('500');\n",
       "      $('#toggleButton').val('Show Code')\n",
       "    } else {\n",
       "      $('div.input').show('500');\n",
       "      $('#toggleButton').val('Hide Code')\n",
       "    }\n",
       "    code_shown = !code_shown\n",
       "  }\n",
       "\n",
       "  $( document ).ready(function(){\n",
       "    code_shown=false;\n",
       "    $('div.input').hide()\n",
       "  });\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis\n",
    "\n",
    "## Explanation of Notebook\n",
    "\n",
    "This notebook started out addressing a dataset related to my internship with Earth Economics. I was asked to read through a research paper (PDF shown below), and use the sensitivity analysis method shown on the data provided to me related to the organizations project. I am not able to show the data from Earth Economics, but I can show the process applied to the data in the research paper shown below.\n",
    "\n",
    "To start off, I will show the data and tables in the research paper, along with how each quantity is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width = 90% height = 700 src = https://agrilife.org/kreuter/files/2013/01/Change-in-ecosystem-service-values-in-SanAntonio-areaTexas_6.pdf></iframe"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"https://agrilife.org/kreuter/files/2013/01/Change-in-ecosystem-service-values-in-SanAntonio-areaTexas_6.pdf\"\n",
    "HTML(\"<iframe width = 90% height = 700 src = \" + file + \"></iframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of Data\n",
    "\n",
    "So the goal of this research paper, and what we were trying to do at Earth Economics was something called Ecosystem Service Valuation (ESV). In the paper above, there are two inputs to this, the number of acres of a given land area and type, and the ecosystem service benefit coefficient corresponding to that land type (in dollars per acre per year). There will be many different land types in a given study area, and each will have a different benefit estimate. \n",
    "\n",
    "The total ecosystem service value of a given study area will be in units of dollars per year. In the paper above there are six land cover types, and the acreage of each was measured through satellite images, and some GIS software. To get the total ESV, each land type benefit coefficient amount (VC) is multiplied by its corresponding acreage, then these are all added together.\n",
    "\n",
    "Put into a formula: $$ESV = \\sum_{i=1}^{n} VC_i \\cdot A_i \\\\ $$\n",
    "$$VC_i = \\text{benefit coefficient amount for land type i} \\\\ $$\n",
    "$$A_i = \\text{number of Acres for land type i} \\\\ $$\n",
    "$$\\text{The sum is over the n land types} \\\\ $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_table(head, row):\n",
    "    cols = len(head)\n",
    "    head_text = '<tr>'\n",
    "    for header in head:\n",
    "        head_text += '<th>' + str(header) + '</th>'\n",
    "    head_text += '</tr>'\n",
    "    row_text = ''\n",
    "    counter = 0\n",
    "    for element in row:\n",
    "        if counter == 0:\n",
    "            row_text += '<tr>'\n",
    "        counter += 1\n",
    "        row_text += '<td>' + str(element) + '</td>'\n",
    "        if counter == cols:\n",
    "            row_text += '</tr>'\n",
    "            counter = 0\n",
    "    html_code = str(head_text) + str(row_text)\n",
    "    return html_code\n",
    "def html_tables(tables, cols):\n",
    "    counter = 0\n",
    "    position = ['left','center','right']\n",
    "    text = '<html>'\n",
    "    for table in tables:\n",
    "        text += '<table align=' + position[counter] + '>' + table + '</table>'\n",
    "        counter += 1\n",
    "        if counter == cols:\n",
    "            counter = 0\n",
    "    text += '</html>'\n",
    "    \n",
    "    return HTML(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><table align=left><tr><th>Land Cover<br>categories</th><th>Equivalent biome</th><th>Ecosystem service<br />coefficient<br>($/ha per year)</th></tr><tr><td>Rangeland</td><td>Grass/rangelands</td><td>232</td></tr><tr><td>Woodland</td><td>Temperate/boreal forest</td><td>302</td></tr><tr><td>Bare Soil</td><td>Cropland</td><td>92</td></tr><tr><td>Residential</td><td>Urban</td><td>0</td></tr><tr><td>Commercial</td><td>Urban</td><td>0</td></tr><tr><td>Transportation</td><td>Urban</td><td>0</td></tr></table><table align=center><tr><th>Land-Use Category</th><th>Total Area (ha)<br>____<br>1976</th><th><br>____<br>1985</th><th><br>____<br>1991</th></tr><tr><td>Rangeland</td><td>80,497</td><td>59,126</td><td>27,896</td></tr><tr><td>Woodland</td><td>8,886</td><td>25,336</td><td>44,654</td></tr><tr><td>Bare Soil</td><td>6,353</td><td>13,514</td><td>13,047</td></tr><tr><td>Residential</td><td>11,499</td><td>10,087</td><td>16,655</td></tr><tr><td>Commercial</td><td>6,116</td><td>10,457</td><td>15,362</td></tr><tr><td>Transportation</td><td>25,748</td><td>23,060</td><td>23,857</td></tr></table><table align=left><tr><th>Land-Use Category</th><th>ESV<br>____<br>1976</th><th>(US$×10^6<br>____<br>1985</th><th>per  year)<br>____<br>1991</th></tr><tr><td>Rangeland</td><td>18.68</td><td>13.72</td><td>6.47</td></tr><tr><td>Woodland</td><td>2.68</td><td>7.65</td><td>13.49</td></tr><tr><td>Bare Soil</td><td>0.58</td><td>1.24</td><td>1.20</td></tr><tr><td>Urban Categories</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><td>Total</td><td>21.94</td><td>22.61</td><td>21.16</td></tr></table><table align=center><tr><th>Change  in  valuation  coefficient  (VC)</th><th>ESV<br>____<br>1976</th><th><br>____<br>1991</th><th>CS<br>____<br>1976</th><th><br>____<br>1991</th></tr><tr><td>Rangeland  VC+50%</td><td>31.28</td><td>24.39</td><td>0.85</td><td>0.31</td></tr><tr><td>Rangeland  VC-50%</td><td>12.61</td><td>17.92</td><td>0.85</td><td>0.31</td></tr><tr><td>Woodland  VC+50%</td><td>23.28</td><td>27.90</td><td>0.12</td><td>0.64</td></tr><tr><td>Woodland  VC-50%</td><td>20.60</td><td>14.41</td><td>0.12</td><td>0.64</td></tr><tr><td>Woodland  VC=Rangeland  VC</td><td>21.32</td><td>18.03</td><td>0.12</td><td>0.64</td></tr><tr><td>Bare  soil  VC+50%</td><td>22.24</td><td>21.76</td><td>0.03</td><td>0.06</td></tr><tr><td>Bare  soil  VC-50%</td><td>21.65</td><td>20.56</td><td>0.03</td><td>0.06</td></tr></table></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables = []\n",
    "head = ['Land Cover<br>categories',\n",
    "            'Equivalent biome',\n",
    "            'Ecosystem service<br />coefficient<br>($/ha per year)']\n",
    "row = ['Rangeland','Grass/rangelands','232',\n",
    "        'Woodland','Temperate/boreal forest','302',\n",
    "        'Bare Soil','Cropland','92',\n",
    "        'Residential','Urban','0',\n",
    "        'Commercial','Urban','0',\n",
    "        'Transportation','Urban','0']\n",
    "\n",
    "head1 = ['Land-Use Category', \n",
    "            'Total Area (ha)<br>____<br>1976',\n",
    "            '<br>____<br>1985',\n",
    "            '<br>____<br>1991']\n",
    "row1 = ['Rangeland', '80,497','59,126','27,896',\n",
    "        'Woodland','8,886', '25,336','44,654',\n",
    "        'Bare Soil','6,353','13,514','13,047',\n",
    "        'Residential','11,499','10,087','16,655',\n",
    "        'Commercial','6,116','10,457','15,362',\n",
    "        'Transportation','25,748','23,060','23,857']\n",
    "\n",
    "head2 = ['Land-Use Category', \n",
    "            'ESV<br>____<br>1976',\n",
    "            '(US$×10^6<br>____<br>1985',\n",
    "            'per  year)<br>____<br>1991']\n",
    "row2 = ['Rangeland', '18.68','13.72','6.47',\n",
    "        'Woodland','2.68', '7.65','13.49',\n",
    "        'Bare Soil','0.58','1.24','1.20',\n",
    "        'Urban Categories','0.00','0.00','0.00',\n",
    "        'Total','21.94','22.61','21.16']\n",
    "\n",
    "head3 = ['Change  in  valuation  coefficient  (VC)', \n",
    "            'ESV<br>____<br>1976',\n",
    "            '<br>____<br>1991',\n",
    "            'CS<br>____<br>1976',\n",
    "            '<br>____<br>1991']\n",
    "row3 = ['Rangeland  VC+50%', '31.28','24.39','0.85','0.31',\n",
    "        'Rangeland  VC-50%','12.61', '17.92','0.85','0.31',\n",
    "        'Woodland  VC+50%','23.28','27.90','0.12','0.64',\n",
    "        'Woodland  VC-50%','20.60','14.41','0.12','0.64',\n",
    "        'Woodland  VC=Rangeland  VC','21.32','18.03','0.12','0.64',\n",
    "        'Bare  soil  VC+50%','22.24','21.76','0.03','0.06',\n",
    "        'Bare  soil  VC-50%','21.65','20.56','0.03','0.06']\n",
    "\n",
    "heads = [head, head1, head2,head3]\n",
    "rows = [row, row1, row2,row3]\n",
    "\n",
    "for i in range(len(heads)):\n",
    "    tables.append(html_table(heads[i], rows[i]))\n",
    "\n",
    "html_tables(tables, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The elasticity equation from Urs' paper, and its independence from the adjustment percentage\n",
    "\n",
    "**The equation in Urs' paper for the coefficient of sensitivity (CS) of the adjusted ESV with respect to the adjusted VC for a given adjustment x is:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$CS_x = \\frac{\\frac{ESV_x - ESV}{ESV}}{\\frac{VC_{kx} - VC_k}{VC_k}} \\\\ $$\n",
    "$$\\text{For any given adjustment percentage x and land type k, and using the ESV definition above:} \\\\ $$\n",
    "$$ESV_x = ESV - (A_k\\cdot VC_k) + (A_k\\cdot (x\\cdot VC_k)) \\\\ $$\n",
    "$$\\text{So:} \\ ESV_x = ESV + (x-1)\\cdot (A_k\\cdot VC_k) \\\\ $$\n",
    "$$\\text{Similarly, the adjustment to} \\ VC_k, \\ VC_{kx} = x\\cdot VC_k \\\\ $$\n",
    "$$\\text{If we subsitute the values above for} \\ ESV, \\ ESV_x, \\ VC_k, \\ VC_{kx}, \\text{the numerator will be:} \\\\ $$ $$\\frac{(ESV + (x-1)\\cdot (A_k\\cdot VC_k)) - ESV}{ESV} \\\\ $$\n",
    "$$\\text{and canceling out the ESV terms on top:} \\quad\\ \\frac{(x-1)\\cdot A_k\\cdot VC_k}{ESV} \\\\ $$\n",
    "$$\\text{For the denominator, we have} \\ \\frac{x\\cdot VC_k - VC_k}{VC_k} = \\frac{(x-1)\\cdot VC_k}{VC_k} = (x-1) \\\\ $$ \n",
    "$$\\text{Combining the numerator and the denominator:} \\ CS_x = \\frac{(x-1)\\cdot A_k\\cdot VC_k}{ESV\\cdot (x-1)} \\\\ $$\n",
    "$$\\text{Canceling out the (x-1) terms, we are left with:} \\ CS_x = \\frac{A_k\\cdot VC_k}{ESV} \\\\ $$\n",
    "$$\\text{So, since the coefficient is independent of x:} \\ CS = \\frac{A_k\\cdot VC_k}{ESV}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Midpoint Elasticity formula more generally used in Economics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Define the Midpoint Elasticity formula as: } MP_x = \\frac{\\frac{ESV_x - ESV}{avg(ESV_x, ESV)}}{\\frac{VC_{kx} - VC_k}{avg(VC_{kx}, VC_k)}} \\\\ $$\n",
    "$$\\text{Simplifying the fraction, we get: } MP_x = \\frac{(ESV_x - ESV)\\cdot avg(VC_{kx}, VC_x)}{(VC_{kx} - VC_x)\\cdot avg(ESV_x, ESV)} \\\\ $$\n",
    "$$ESV_x - ESV = (x-1)\\cdot A_k\\cdot VC_k \\\\ $$\n",
    "$$avg(ESV_x, ESV) = \\frac{ESV + (x-1)\\cdot A_k\\cdot VC_k + ESV}{2} = \\frac{2\\cdot ESV + (x-1)\\cdot A_k\\cdot VC_k}{2} \\\\ $$\n",
    "$$VC_{kx} - VC_x = x\\cdot VC_k - VC_k = (x-1)\\cdot VC_k \\\\ $$\n",
    "$$avg(VC_{kx}, VC_x) = \\frac{x\\cdot VC_k + VC_k}{2} = \\frac{(x+1)\\cdot VC_k}{2} \\\\ $$\n",
    "$$(ESV_x - ESV)\\cdot avg(VC_{kx}, VC_x) = \\frac{((x-1)\\cdot A_k\\cdot VC_k)\\cdot ((x+1)\\cdot VC_k)}{2} \\\\ $$\n",
    "$$(VC_{kx} - VC_x)\\cdot avg(ESV_x, ESV) = \\frac{((x-1)\\cdot VC_k)\\cdot (2\\cdot ESV + (x-1)\\cdot A_k\\cdot VC_k)}{2} \\\\ $$\n",
    "$$\\text{Putting this together into one fraction, we can cancel out two of the (x-1)'s, two of the } VC_k\\text{, and the two 2's} \\\\ $$\n",
    "$$MP_x = \\frac{(x+1)\\cdot A_k\\cdot VC_k}{2\\cdot ESV + (x-1)\\cdot A_k\\cdot VC_k}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the data for elasticity calculations and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries for processing the data\n",
    "import seaborn as sns #Statistical graphing library\n",
    "import matplotlib.pyplot as plt #Basic graphing library\n",
    "import random #Library for random number generation\n",
    "from decimal import *\n",
    "getcontext().prec = 4\n",
    "\n",
    "#Setting so that the graphs appear within this notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I grouped the data by Land Cover Type, Land Use, Ecosystem Service, Value Type, County, and MLRA.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions to calculate and graph the elasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elasticity(attribute): #Function to calculate elasticity as per Urs' equation\n",
    "    \n",
    "    #Define dictionaries to store the values\n",
    "    low_elasticity, high_elasticity = {}, {}\n",
    "    attributes = list(data[attribute].unique())\n",
    "    \n",
    "    low_data = data[data['Value Type'] == 'Low']\n",
    "    high_data = data[data['Value Type'] == 'High']\n",
    "    \n",
    "    for unit in attributes:\n",
    "        low_unit_data = data[(data[attribute] == unit)&\n",
    "                             (data['Value Type'] == 'Low')]\n",
    "        high_unit_data = data[(data[attribute] == unit)&\n",
    "                              (data['Value Type'] == 'High')]\n",
    "        \n",
    "        low_elasticity[str(unit)], high_elasticity[str(unit)] = 0, 0\n",
    "\n",
    "        low_unit_ESV = np.sum(low_unit_data['#Acres']*\n",
    "                              low_unit_data['$/acre/year']*\n",
    "                              low_unit_data['Health_Index'])\n",
    "        low_ESV = np.sum(low_data['#Acres']*\n",
    "                         low_data['$/acre/year']*\n",
    "                         low_data['Health_Index'])\n",
    "        high_unit_ESV = np.sum(high_unit_data['#Acres']*\n",
    "                               high_unit_data['$/acre/year']*\n",
    "                               high_unit_data['Health_Index'])\n",
    "        high_ESV = np.sum(high_data['#Acres']*\n",
    "                          high_data['$/acre/year']*\n",
    "                          high_data['Health_Index'])\n",
    "                \n",
    "        low_elasticity[str(unit)] = low_unit_ESV/low_ESV\n",
    "        high_elasticity[str(unit)] = high_unit_ESV/high_ESV\n",
    "    \n",
    "    return low_elasticity, high_elasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint_elasticity(attribute, adjustments):\n",
    "    \n",
    "    low_elasticity, high_elasticity = {}, {}\n",
    "    attributes = list(data[attribute].unique())\n",
    "    low_data = data[data['Value Type'] == 'Low']\n",
    "    high_data = data[data['Value Type'] == 'High']\n",
    "    x = 0\n",
    "    \n",
    "    for unit in attributes:\n",
    "        low_unit_data = data[(data[attribute] == unit)&\n",
    "                             (data['Value Type'] == 'Low')]\n",
    "        high_unit_data = data[(data[attribute] == unit)&\n",
    "                              (data['Value Type'] == 'High')]\n",
    "        \n",
    "        low_elasticity[str(unit)], high_elasticity[str(unit)] = [], []\n",
    "        \n",
    "        for pct in adjustments:\n",
    "            x = (100 + pct)/100\n",
    "            \n",
    "            low_unit_ESV = np.sum(low_unit_data['#Acres']*\n",
    "                                  low_unit_data['$/acre/year']*\n",
    "                                  low_unit_data['Health_Index'])\n",
    "            low_ESV = np.sum(low_data['#Acres']*\n",
    "                             low_data['$/acre/year']*\n",
    "                             low_data['Health_Index'])\n",
    "            high_unit_ESV = np.sum(high_unit_data['#Acres']*\n",
    "                                   high_unit_data['$/acre/year']*\n",
    "                                   high_unit_data['Health_Index'])\n",
    "            high_ESV = np.sum(high_data['#Acres']*\n",
    "                              high_data['$/acre/year']*\n",
    "                              high_data['Health_Index'])\n",
    "            \n",
    "            MP_low = ((x+1)*(low_unit_ESV))/((2*low_ESV) + (x-1)*(low_unit_ESV))\n",
    "            MP_high = ((x+1)*(high_unit_ESV))/((2*high_ESV) + (x-1)*(high_unit_ESV))\n",
    "            low_elasticity[str(unit)].append(MP_low)\n",
    "            high_elasticity[str(unit)].append(MP_high)\n",
    "                                              \n",
    "    return low_elasticity, high_elasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_by_attribute(low_elasticity, high_elasticity, attribute, adjustments, midpoint = True):\n",
    "        \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize = (12,30), \n",
    "                                   sharey = True, sharex = False)\n",
    "    low_plot = []\n",
    "    high_plot = []\n",
    "    attributes = sorted(list(data[attribute].unique()), reverse = True)\n",
    "    \n",
    "    for unit in attributes:\n",
    "        ax1.plot(adjustments, low_elasticity[str(unit)], label = str(unit))\n",
    "        ax2.plot(adjustments, high_elasticity[str(unit)], label = str(unit))\n",
    "\n",
    "    ax1.set_xlabel('Percent Adjustment'); ax2.set_xlabel('Percent Adjustment')\n",
    "    if midpoint:\n",
    "        ax1.set_title('Low Estimate: Midpoint Formula'); ax1.set_ylabel('Elasticity')\n",
    "        ax2.set_title('High Estimate: Midpoint Formula'); ax2.set_ylabel('Elasticity')\n",
    "    else:\n",
    "        ax1.set_title(\"Low Estimate: Urs' Formula\"); ax1.set_ylabel('Elasticity')\n",
    "        ax2.set_title(\"High Estimate: Urs' Formula\"); ax2.set_ylabel('Elasticity')\n",
    "    ax1.legend(loc = 'upper left', ncol = 3, fancybox = True); ax2.legend(loc = 'upper left', ncol = 3)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_by_estimate(low_elasticity, high_elasticity, attribute, midpoint = True):\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15,30), \n",
    "                                   sharey = True, sharex = True)\n",
    "    low_plot = []\n",
    "    high_plot = []\n",
    "    attributes = sorted(list(data[attribute].unique()), reverse = True)\n",
    "    \n",
    "    for unit in attributes:\n",
    "        low_plot.append(np.mean(low_elasticity[str(unit)]))\n",
    "        high_plot.append(np.mean(high_elasticity[str(unit)]))\n",
    "\n",
    "    x_range = list(range(len(attributes)))\n",
    "    ax1.set_yticks(x_range)\n",
    "    ax1.set_yticklabels(attributes)\n",
    "    ax2.set_yticks(x_range)\n",
    "    ax2.set_yticklabels(attributes)\n",
    "    \n",
    "    ax1.barh(bottom = x_range, width = low_plot, label = 'Low Estimate')\n",
    "    ax2.barh(bottom = x_range, width = high_plot, label = 'High Estimate')\n",
    "    if midpoint:\n",
    "        ax1.set_title(\"Low Estimate: Midpoint Formula\"); ax1.set_xlabel('Elasticity')\n",
    "        ax2.set_title(\"High Estimate: Midpoint Formula\"); ax2.set_xlabel('Elasticity')\n",
    "    else:\n",
    "        ax1.set_title(\"Low Estimate: Urs' Formula\"); ax1.set_xlabel('Elasticity')\n",
    "        ax2.set_title(\"High Estimate: Urs' Formula\"); ax2.set_xlabel('Elasticity')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Simulation Functions and Methodology in the Literature\n",
    "\n",
    "**Most of the methods I found in the ecosystem literature and in the academic literature in general involve running simulations by pulling random values for each input and assessing the effects on the output.**\n",
    "\n",
    "**Literature examples:**\n",
    "\n",
    "*From screening to quantitative sensitivity analysis. A unified approach*\n",
    "\n",
    "*Sensitivity analysis ecosystem service valuation Sanchez-Canales et al 2012*\n",
    "\n",
    "*Sensitivity analysis: how to detect important factors in large models*\n",
    "\n",
    "\n",
    "**In general, these types of methods are used for complex models where the partial derivative with respect to the inputs are to laborous/impossible to calculate. Many of these methods (such as the Morris/Elementary Effects method) are just aggregates of the estimates of the derivates**\n",
    "\n",
    "**For this data and model, it is possible to calculate the partial derivatives with respect to each of the inputs ($/acre/year, Health Score, and #Acres)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{As above: The total ecosystem service value is:} \\ ESV = \\sum_{i=1}^{n} A_i\\cdot VC_i \\\\ $$\n",
    "$$A_i =\\text{Acres} \\quad\\ VC_i =\\frac{\\text{Dollars}}{\\text{Acre}\\cdot \\text{Year}} n =\\text{Number of Land Types} \\\\ $$\n",
    "$$\\text{The valuation coefficient for the kth attribute in the category is:} \\ VC_k \\\\ $$\n",
    "$$\\text{The partial derivative of the total ESV with respect to the kth valuation coefficients } VC_k \\ \\text{is: } \\\\ $$\n",
    "$$\\frac{\\partial}{\\partial VC_k}(\\sum_{i=1}^{n} A_i\\cdot VC_i) = \\sum_{i=1}^{n} \\frac{\\partial}{\\partial VC_k}(A_i\\cdot VC_i) \\\\ $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data():\n",
    "    test_data = data\n",
    "    test_data['$/acre/year'] = test_data.apply(lambda x: \n",
    "                                               np.random.uniform(.75*x['Low $/acre/year'], \n",
    "                                                                 1.25*x['High $/acre/year']), axis = 1)\n",
    "    return test_data\n",
    "\n",
    "def ESV_by_attribute(test_data, attribute):\n",
    "    ESV_dict = {}\n",
    "    attributes = list(test_data[attribute].unique())\n",
    "    total = np.sum(test_data['#Acres']*test_data['Health_Index']*test_data['$/acre/year'])\n",
    "    ESV_dict['Total'] = total\n",
    "    \n",
    "    for element in attributes:\n",
    "        test_data_trim = test_data[test_data[attribute] == element]\n",
    "        total_trim = np.sum(test_data_trim['#Acres']*\n",
    "                            test_data_trim['Health_Index']*\n",
    "                            test_data_trim['$/acre/year'])\n",
    "        ESV_dict[str(element)] = total_trim\n",
    "        \n",
    "    return ESV_dict\n",
    "\n",
    "def VC_by_attribute(test_data, attribute):\n",
    "    VC_dict = {}\n",
    "    attributes = list(test_data[attribute].unique())\n",
    "    total = np.sum(test_data['$/acre/year'])\n",
    "    VC_dict['Total'] = total\n",
    "    \n",
    "    for element in attributes:\n",
    "        test_data_trim = test_data[test_data[attribute] == element]\n",
    "        total_trim = np.sum(test_data_trim['$/acre/year'])\n",
    "        VC_dict[str(element)] = total_trim\n",
    "        \n",
    "    return VC_dict\n",
    "\n",
    "def monte_carlo(NumTrials, attribute):\n",
    "    \n",
    "    attributes = list(data[attribute].unique())\n",
    "    ESV_vals, VC_vals = {}, {}\n",
    "    ESV_vals['Total_ESV'], VC_vals['Total_VC'] = [], []\n",
    "    \n",
    "    for element in attributes:\n",
    "        VC_vals[str(element) + '_VC'], ESV_vals[str(element) + '_ESV'] = [], []\n",
    "        \n",
    "    for trial in range(NumTrials):\n",
    "        \n",
    "        test_data = get_test_data()\n",
    "        ESV_dict = ESV_by_attribute(test_data, attribute)\n",
    "        VC_dict = VC_by_attribute(test_data, attribute)\n",
    "        ESV_vals['Total_ESV'].append(ESV_dict['Total'])\n",
    "        VC_vals['Total_VC'].append(VC_dict['Total'])\n",
    "        for element in attributes:\n",
    "            VC_vals[str(element) + '_VC'].append(VC_dict[element])\n",
    "            ESV_vals[str(element) + '_ESV'].append(ESV_dict[element])\n",
    "    \n",
    "    plot_data = pd.concat([pd.DataFrame.from_dict(ESV_vals),\n",
    "                           pd.DataFrame.from_dict(VC_vals)], axis = 1)\n",
    "    \n",
    "    return plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian(attribute, variable):\n",
    "    attributes = list(data[attribute].unique())\n",
    "    cols = ['#Acres', 'Low $/acre/year', 'High $/acre/year', 'Health_Index']\n",
    "    if variable == '$/acre/year':\n",
    "        variables = ['Low $/acre/year', 'High $/acre/year']\n",
    "    else:\n",
    "        variables = variable\n",
    "    cols.remove(variables)\n",
    "    print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
